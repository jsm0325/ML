

***비지도 학습 ***

주요 내용 : 군집 , 가우시안 혼합

대부분의 머신러닝 애플리케이션이 지도 학습 기반이지만 , 사용할 수 있는 데이터는 대부분 레이블이 없음 
실질적으로 잠재력이 가장 큼 

*군집
-비슷한 샘플을 클러스터로 모음
-데이터 분석, 고객 분류, 추천 시스템, 검색 엔진, 이미지 분할, 준지도 학습, 차원 축소 등에 사용하는 훌륭한 도구

 군집에 밀도를 이용하여서 *이상치 탐지를 할 수 있다.
밀도가 낮은 영역에 놓인 샘플이 이상치일 가능성이 높음.
*이상치 탐지 : 정상 데이터가 어떻게 보이는지를 학습하고, 비정상 샘플을 감지하는 데 사용

군집은 비슷한 샘플을 구별해 하나의 클러스터 또는 비슷한 샘플의 그룹으로 할당하는 작업을 한다.

*군집을 사용하는 다양한 어플리케이션 
고객 분류, 데이터 분석, 차원 축소 기법,이상치 탐지, 준지도 학습, 검색 엔진 등이 있다.

*K-평균 
반복 몇 번으로 레이블이 없는 데이터셋을 빠르고 효율적으로 클러스터로 묶는 간단한 알고리즘 
여기서 키 아이디어는 군집의 중심을 찾는 것이다. 센터를 먼저 찾은 후 샘플이 분포된 거리를 측정하여 
가장 가까운 샘플로 할당을 시키면 된다. 

*결정경계 
평면을 특정 점까지의 거리가 가장 가까운 점의 집합으로 분할한 그림인 보로노이 다이어그램을 이용함

*k-평균 알고리즘의 단점
군집의 크기가 서로 많이 다르면 잘 작동하지 않는다. 그 이유는 샘플과 센트로이드까지의 거리만 고려되기 때문

*하드군집 - 각 샘플에 대해 가장 가까운 클러스터를 선택
*소프트 군집- 클러스터마다 샘플에 점수를 부여함. 샘플별로 각 군집 센트로이드와의 거리를 측정

*K-평균 알고리즘
처음에는 센트로이드를 랜덤하게 선정하고
수렴할 때까지 각 샘플을 가장 가까운 센트로이드에 할당하고, 군집별로 샘플의 평균을 계산하여 	
새로운 센트로이드를 지정한다
역시나 센트로이드를 랜덤하게 선정하기 때문에 최적이 아닌 솔루션이 될 수도 있다.

*관성 (inertia, 이너셔)
정의 : 샘플과 가장 가까운 센트로이드와의 거리의 제곱의 합
사이킷런에서 K-mean를 이용하여 각 군집이 센트로이드에 얼마나 가까이 모여있는가를 측정한다.
score()메서드가 측정(음수 기준)

*좋은 모델 선택법
다양한 초기화 과정을 심험한 후에 가장 좋은 것 선택
n=init = 10이 기본값으로 사용됨
10번 학습 후 가장 낮은 관성을 갖는 모델 선택.

*elkan 알고리즘 
불필요한 거리 계산을 많이 피함으로 학습 속도가 향삼됨

*미니배치 k-평균
전체 데이터셋 대신 각 반복마다 미니배치를 사용해 센트로이드를 조금씩 이동함.
미니배츠를 지원하는 k-평균 알고리즘

*미니배치 k-평균의 특징
k-평균 알고리즘보다 훨씬 빠름
이너셔는 일반적으로 조금 더 나쁨
군집수가 증가할 때 이너셔는 더 나쁨

*관성과 클러스터 
클러스터 개수k가 증가할 수록 관성이 작아지므로, 좋은 성능 지표가 아님.
관성만으로 모델을 평가할 수 없음.
관성이 더 이상 획기적으로 줄어들지 않는 지점의 클러스터 개수 선택 

*실루엣 점수와 클러스터 개수
실루엣 점수 
-모든 샘플에 대한 실루엣 계수의 평균 
실루엣 계수 -1과 +1사이의 값
 -+1에 가까운 값: 자신의 클러스터 안에 포함되고, 다른 클러스터와는 멀리 떨어짐.
-0에 가까운 값 : 클러스터 경계에 위치
- -1에 가까운 값 : 샘플이 잘못된 클러스터에 할당됨

*실루엣 다이어그램
-클러스터별 실루엣 계수 모음 . 칼 모양에 그래프이다
칼두께 : 클러스터에 포함된 샘플의 개수
칼 길이 : 클러스터에 포함된샘플의 실루엣 계수 (길 수록 좋음)

*빨간 파선 : 클러스트 계수에 해당하는 실루엣 점수
-대부분의 칼이 빨간 파선보다 길어야 함
-칼의 두께가 서로 비슷해야, 즉 클러스터별 크기가 비슷해야 좋은 모델이다.

결론적으로 최적의 클러스터 개수를 찾는 방법으로 실루엣 점수를 활용하여서
실루엣 다이어그램에서 칼이 두께가 클러스터별로 비슷한 것이 좋은 모델이라고 할 수있다.

************ 페어 질문 *****************************************
(서로 질문을 하고 답변을 하면서 진행함 )
최적의 클러스터 개수를 정하는 방법으로 가장 좋은 것은 무엇인가 ?에 대해서 이야기를 나누어봤다.

이 부분에 대해서 서로 의견이 맞았던 부분은 관성보다 실루엣 기법을 사용하는 것이 
최적의 클러스터 개수를 정하는 방법이라고 생각을 했다. 
그 이유로는 최적의 군집수를 사용하지 않으면 적절하지 못한 모델을 학습할 수 있기 때문에
최적의 군집수를 정하는 것이 매우 중요하다고 서로 이야기를 했고, 
페어가  그 부분에 대해서는 관성만으로 평가하기에는 너무 부족하다고 이야기를 했다.
그래서 서로  
실루엣 기법이 여러 클러스터링 기법으로 군집화를 여러번 한 후에 실루렛 계수의 평균값을 비교하기 때문에 클러스터 개수를 몇개로 할 지 정하기 쉽다고 생각을 했다.
이러한 이유로 실루엣 기법이 더 최적의 클러스터 개수를 정하는 방법이라고 생각을 했다.

(위 내용은 서로 이야기를 나누며 질문과 답변으로 고민을 했습니다)
*****************************************************************

*k-평균의 한계
최적이 아닌 솔루션을 피하려면 알고리즘을 여러 번 실행해야 함
클러스터 개수를 미리 지정해야 함
클러스터의 크기나 밀집도가 다르거나, 원형이 아닐 경우 잘 작동하지 않음.

**군집을 사용한 전처리**

* 미니 mnist 데이터셋 전처리
전처리 없이 로지스틱회귀 학습시키면 96.89% 정확도임.

*k-평균을 전처리 단계로 사용한 후 로지스틱회귀 학습
훈련 세트를 50개의 클러스터로 모음
군집에서 데이터셋의 차원은 64->50으로 감소
정확도 97.78%로 증가 

*클러스터 개수 k를 임의로 정하지 않고, gridsearchcv를 사용해 최적의 클러스터 개수를 찾음
최적 군집수 :99
모델 정확도 : 98.22%

** 군집을 사용한 준지도 학습**
레이블이 없는 샘플이 많고 레이블이 있는 샘플이 적을 때 사용한다.

*레이블 전파 
레이블을 동일한 클러스터에 있는 모든 샘플로 전파

군집에 속한 전체 샘플보다 센트로이드에 가까운 20% 정도에게만 레이블 전파 후 학습 
센트로이드에 가깝기 때문에 레이블의 정확도가 매우 높음
전파된 레이블이 실제로 매우 좋기 때문에 결과가 좋음

**DBSCAN**
밀집된 연속적 지역을 클러스터로 정의
 
두개의 하이퍼파라미터 사용 
eps , min_samples 

*DBSCAN의 장단점
매우 간단하면서 매우 강력한 알고리즘 
군집의 모양과 개수에 상관이 없으며 이상치에 안정적이다.

**가우시안 혼합 모델 **

샘플이 파라미터가 알려지지 않은 여러 개의 혼합된 가우시안 분포에서 생성되었다고 가정하는 확률 모델

가우시안 분포 = 정규분호

가우시안 혼합 - EM알고리즘

평균 , 표준편차, 가중치(그룹들 간의 데이터 비율 - 라벨별 가중치합)
*라벨을 얻기 위해서는 분포가 필요하고, 분포를 얻기 위해서는 라벨이 필요함.

초기값은 랜덤하게 확률값을 넣고 
likelihood 비교로 라벨링을 하고 각 그룹별 모수를 추정한 후에 
추정된 모수를 이용한 각 그룹별 분포 도시하는 단계를 반복한다.

*GMM모델 
타원형 모델에 대해서 학습하기 쉽게 도와준다 

*GMM 모델 규제 
특성수가 크거나, 군집수가 많거나, 샘플이 적은 경우 최적 모데 학습이 어려움
이때 공분산에 규제를 가해서 학습을 도와줄 수 있다.

*가우시안 혼합을 사용한 이상치 탐지 
이상치 탐지 : 
보통과 많이 다른 샘플을 감지하는 작업

*가우시안혼합 모델 활용한 이상치 탐지
밀도가 임계값보다 낮은 지역에 있는 샘플을 이상치로 간주 가능

* 클러스터 개수 선택하기 
k-평균에서 사용했던 관성 또는 실루엣 점수 사용 불가.
군집이 타원형일 때 값이 일정하지 않기 때문
이론적 정보 기준을 최소화 하는 모델 선택 가능 

*이론적 정보 기준 
BIC , AIC


